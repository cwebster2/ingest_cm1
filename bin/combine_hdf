#!/usr/bin/env python3

#####################################################################
#
#   combine_hdf
#
#   This python script recombines tiled MPI output from CM1.  Given
#   a directory with HDF5 MPI output cdirs, this script will combine
#   each tiled timestep into a single HDF5 file.  This script will
#   process every output variable present and handles output on each
#   of the grids (scalar, u, v, w).
#
#   Copyright (C) 2014 Casey Webster - All Rights Reserved
#   You may use, distribute and modiy this code under the
#   terms of the BSD (3-clause) license.
#
#   You should have received a copy of the BSD (3-clause)
#   license with this file.  If not, please visit :
#   http://opensource.org/licenses/BSD-3-Clause or 
#   https://github.com/cwebster2/ingest_cm1/blob/master/LICENSE
#
#####################################################################

#TODO: comment this code!

import argparse
import os.path
import glob
import re
import h5py
import numpy as np
import sys

def main():
   parser = argparse.ArgumentParser()
   parser.add_argument( '-d', '--dset', dest='dsetname', required=True, help="Dataset base name")
   parser.add_argument( '-p', '--path', dest='dsetpath', required=True, help="Path to HDF5 cdirs.")
   args = parser.parse_args()

   dsetname = args.dsetname
   dsetpath = args.dsetpath

   dirmatch = "{0}.*.cdir".format(os.path.join(dsetpath,dsetname))
   print("\nCombine HDF inovked for {0}\n".format(dirmatch))

   print("Scanning for times\n")

   hdfdirs = glob.glob(dirmatch)

   times = []

   for dir in hdfdirs:
      fname = dir
      m = re.search("{0}.(\d+).cdir".format(os.path.join(dsetpath,dsetname)),fname)
      if m:
         time = m.groups()[0]
         times.append((time, fname))

   for time in times:
      process_time(time, dsetname)


def process_time(time, dsetname):
   print("Processing time {0} in {1}".format(time[0],time[1]))

   fnames = glob.glob("{0}/*.cm1hdf5".format(time[1]))

   files = [None] * len(fnames)
   h5files = [None] * len(fnames)

   for fname in fnames:
      m = re.search("{0}.{1}_(\d+).cm1hdf5".format(dsetname,time[0]),fname)
      if m:
        files[int(m.groups()[0])] = fname
        h5files[int(m.groups()[0])] = h5py.File(fname, 'r+')

   print("  Found cm1hdf5 fileset for time {0}".format(time[0]))
   for file in files:
      print("    {0}".format(os.path.basename(file)))
   
   print("  Reading metadata from file 0")
   dsettime = int(h5files[0]['/time'][()])
   nodex = int(h5files[0]['/grid/nodex'][()])
   nodey = int(h5files[0]['/grid/nodey'][()])
   nx = int(h5files[0]['/grid/nx'][()])
   ny = int(h5files[0]['/grid/ny'][()])
   nz = int(h5files[0]['/grid/nz'][()])
   ni = int(h5files[0]['/grid/ni'][()])
   nj = int(h5files[0]['/grid/nj'][()])
   
   print("    Dataset time {0}".format(dsettime))
   print("    MPI NODES ({0},{1})".format(nodex,nodey))
   print("    Dataset dimensions ({0}, {1}, {2})".format(nx,ny,nz))

   outfname = os.path.join(os.path.dirname(time[1]),"{0}.{1}.h5".format(dsetname,time[0]))
   print("  Initializing output file: {0}".format(outfname))
   outfile = h5py.File(outfname, 'w')
   
   print("  Copying metadata, grids, meshes and basestate...",end='')
   #===================================================================
   grid = outfile.create_group('/grid')
   mesh = outfile.create_group('/mesh')
   basestate = outfile.create_group('/basestate')
   basestate3d = outfile.create_group('/3d_basestate')
   twod = outfile.create_group('/2d')
   threed = outfile.create_group('/3d_s')
   threed_u = outfile.create_group('/3d_u')
   threed_v = outfile.create_group('/3d_v')
   threed_w = outfile.create_group('/3d_w')

   #===================================================================
   # Transferring values that do not need translation
   move_scalar_dset(h5files[0], outfile, 'time')
   move_scalar_dset(h5files[0], outfile, '/grid/nx')
   move_scalar_dset(h5files[0], outfile, '/grid/ny')
   move_scalar_dset(h5files[0], outfile, '/grid/nz')
   move_scalar_dset(h5files[0], outfile, '/grid/x0')
   move_scalar_dset(h5files[0], outfile, '/grid/y0')
   move_scalar_dset(h5files[nodex*nodey-1], outfile, '/grid/x1')
   move_scalar_dset(h5files[nodex*nodey-1], outfile, '/grid/y1')
   move_scalar_dset(h5files[0], outfile, '/mesh/dx')
   move_scalar_dset(h5files[0], outfile, '/mesh/dy')

   frombase = h5files[0]['/basestate']
   for name in frombase:
      move_1d_dset(frombase, basestate, name)

   #===================================================================
   # Recreate meshes for full domain
   xh = np.zeros(nx, np.float32)
   for i in range(nodex):
     xh[i*ni:(i+1)*ni] = h5files[i]['/mesh/xh']
   outfile['/mesh/xh'] = xh
   copy_attrs(h5files[0], outfile, '/mesh/xh')

   xf = np.zeros(nx+1, np.float32)
   for i in range(nodex):
     xf[i*ni:(i+1)*ni] = h5files[i]['/mesh/xf']
     xf[nx] = xf[1]-xf[0] + xf[nx-1]
   outfile['/mesh/xf'] = xf
   copy_attrs(h5files[0], outfile, '/mesh/xf')

   yh = np.zeros(ny, np.float32)
   for j in range(nodey):
     yh[j*nj:(j+1)*nj] = h5files[j*nodex]['/mesh/yh']
   outfile['/mesh/yh'] = yh
   copy_attrs(h5files[0], outfile, '/mesh/yh')

   yf = np.zeros(ny+1, np.float32)
   for j in range(nodey):
     yf[j*nj:(j+1)*nj] = h5files[j*nodex]['/mesh/yf']
     yf[ny] = yf[1]-yf[0] + yf[ny-1]
   outfile['/mesh/yf'] = yf
   copy_attrs(h5files[0], outfile, '/mesh/yf')

   move_1d_dset(h5files[0], outfile, '/mesh/zh') 

   zf = np.zeros(nz+1, np.float32)
   zf[0:nz] = h5files[j*nodex]['/mesh/zf']
   zf[nz] = zf[nz-1]-zf[nz-2] + zf[nz-1]
   outfile['/mesh/zf'] = zf
   copy_attrs(h5files[0], outfile, '/mesh/zf')

   print("Done")

   #===================================================================
   # Process 2D datasets
   print("  2D datasets...",end='')

   from2d = h5files[0]['/2d']
   for name in from2d:
      print("{0}...".format(name),end='')

      ds2d = np.zeros((ny,nx), np.float32)
      dset = "/2d/{0}".format(name)
      
      for j in range(nodey):
        for i in range(nodex):
          #print("X range {0} -- {1}".format(i*ni, (i+1)*ni))
          #print("Y range {0} -- {1}".format(j*nj, (j+1)*nj))
          #print("File #  {0}".format(j*nodex+i))
          #ds2d[i*ni:(i+1)*ni, j*nj:(j+1)*nj] = h5files[j*nodex+i]["/2d/{0}".format(name)]
          ds2d[j*nj:(j+1)*nj, i*ni:(i+1)*ni] = h5files[j*nodex+i][dset]
      outfile[dset] = ds2d
      copy_attrs(h5files[0], outfile, dset)


   print("Done")
   #===================================================================
   # Process 3D basestate
   print("  3D base state datasets...",end='')
   sys.stdout.flush()

   from3d = h5files[0]['/3d_basestate']
   for name in from3d:
      print("{0}...".format(name),end='')
      sys.stdout.flush()
      dset = "/3d_basestate/{0}".format(name)
      (mynz, mynj, myni) = from3d[name].shape
      njp1 = 0
      nip1 = 0
      to3d = basestate_3d
      if (mynz == nz+1):
         ds3d = np.zeros((nz+1,ny,nx), np.float32)
      elif (mynj == nj+1):
         ds3d = np.zeros((nz,ny+1,nx), np.float32)
         njp1 = 1
      elif (myni == ni+1):
         ds3d = np.zeros((nz,ny,nx+1), np.float32)
         nip1 = 1
      else:
         ds3d = np.zeros((nz,ny,nx), np.float32)

      for j in range(nodey):
        for i in range(nodex):
          ds3d[0:mynz, j*nj:(j+1)*nj+njp1, i*ni:(i+1)*ni+nip1] = h5files[j*nodex+i][dset]
      to3d.create_dataset(name, data=ds3d, compression="gzip", compression_opts=2)
      copy_attrs(from3d, to3d, name)


   print("Done")
   #===================================================================
   # Process 3D datasets
   print("  3D datasets...",end='')
   sys.stdout.flush()

   from3d = h5files[0]['/3d']
   for name in from3d:
      print("{0}...".format(name),end='')
      sys.stdout.flush()
      dset = "/3d/{0}".format(name)
      (mynz, mynj, myni) = from3d[name].shape
      njp1 = 0
      nip1 = 0
      if (mynz == nz+1):
         to3d = threed_w
         ds3d = np.zeros((nz+1,ny,nx), np.float32)
      elif (mynj == nj+1):
         to3d = threed_v
         ds3d = np.zeros((nz,ny+1,nx), np.float32)
         njp1 = 1
      elif (myni == ni+1):
         to3d = threed_u
         ds3d = np.zeros((nz,ny,nx+1), np.float32)
         nip1 = 1
      else:
         to3d = threed
         ds3d = np.zeros((nz,ny,nx), np.float32)

      
      for j in range(nodey):
        for i in range(nodex):
          ds3d[0:mynz, j*nj:(j+1)*nj+njp1, i*ni:(i+1)*ni+nip1] = h5files[j*nodex+i][dset]
      to3d.create_dataset(name, data=ds3d, compression="gzip", compression_opts=2)
      copy_attrs(from3d, to3d, name)

#TODO: chunk dims?
#TODO: allow user to specify which datasets to copy
#TODO: allow user to specift slice to copy instead of whole dataset

   print("Done")
   #===================================================================


   #===================================================================
   print("  Closing input files")
   for h5file in h5files:
      h5file.close()
   print("  Closing output files")
   outfile.close()

#======================================================================
def move_scalar_dset(source, dest, dset):
  dest[dset] = source[dset][()]
  copy_attrs(source, dest, dset)

def copy_attrs(source, dest, dset):
  for key in source[dset].attrs:
    dest[dset].attrs[key] = source[dset].attrs[key]

def move_1d_dset(source, dest, dset):
  dest[dset] = source[dset][:]
  copy_attrs(source, dest, dset)

if __name__ == '__main__':
   main()
